"0","# Calculate precision and name it as precision_model_tree"
"0",""
"0","conf_matrix <- confusionMatrix(predict_model_tree, actual_labels)"
"0","conf_matrix"
"1","Confusion Matrix and Statistics

"
"1","          Reference
"
"1","Prediction"
"1"," Good"
"1"," Bad"
"1","
      Good"
"1","  647"
"1"," 142"
"1","
      Bad "
"1","  142"
"1"," 162"
"1","
"
"1",""
"1","                         "
"1","                 "
"1","
"
"1","               Accuracy :"
"1"," 0.7402          "
"1","
"
"1","                 95% CI :"
"1"," (0.7131, 0.7659)"
"1","
"
"1","    No Information Rate :"
"1"," 0.7219          "
"1","
"
"1","    P-Value [Acc > NIR] :"
"1"," 0.09339         "
"1","
"
"1","                         "
"1","                 "
"1","
"
"1","                  Kappa :"
"1"," 0.3529          "
"1","
"
"1","                         "
"1","                 "
"1","
"
"1"," Mcnemar's Test P-Value :"
"1"," 1.00000         "
"1","
"
"1","                         "
"1","                 "
"1","
"
"1","            Sensitivity :"
"1"," 0.8200          "
"1","
"
"1","            Specificity :"
"1"," 0.5329          "
"1","
"
"1","         Pos Pred Value :"
"1"," 0.8200          "
"1","
"
"1","         Neg Pred Value :"
"1"," 0.5329          "
"1","
"
"1","             Prevalence :"
"1"," 0.7219          "
"1","
"
"1","         Detection Rate :"
"1"," 0.5919          "
"1","
"
"1","   Detection Prevalence :"
"1"," 0.7219          "
"1","
"
"1","      Balanced Accuracy :"
"1"," 0.6765          "
"1","
"
"1","                         "
"1","                 "
"1","
"
"1","       'Positive' Class :"
"1"," Good            "
"1","
"
"1","                         "
"1","                 "
"1","
"
"0","precision_model_tree <- conf_matrix$byClass[""Pos Pred Value""]"
"0","precision_model_tree"
"1","Pos Pred Value "
"1","
"
"1","     0.8200253 "
"1","
"
